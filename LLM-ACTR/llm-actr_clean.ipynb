{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLtyWfaHszHy",
        "outputId": "fb93147a-2d38-46d9-b2b9-c57a12df6dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Collecting optimum\n",
            "  Downloading optimum-1.22.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting auto-gptq\n",
            "  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Collecting coloredlogs (from optimum)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.13.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.2.0)\n",
            "Collecting rouge (from auto-gptq)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting gekko (from auto-gptq)\n",
            "  Downloading gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting peft>=0.5.0 (from auto-gptq)\n",
            "  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (3.20.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.22.0-py3-none-any.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.7/453.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, rouge, pyarrow, humanfriendly, gekko, dill, multiprocess, coloredlogs, tokenizers, transformers, peft, datasets, optimum, evaluate, auto-gptq\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed auto-gptq-0.7.1 coloredlogs-15.0.1 datasets-3.0.1 dill-0.3.8 evaluate-0.4.3 gekko-1.2.1 humanfriendly-10.0 multiprocess-0.70.16 optimum-1.22.0 peft-0.13.0 pyarrow-17.0.0 rouge-1.0.1 tokenizers-0.15.2 transformers-4.37.2 xxhash-3.5.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:  \n",
        "    # Installing requisite packages\n",
        "    !pip install datasets transformers==4.37.2 evaluate accelerate optimum auto-gptq\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/VSM_BRIMS_03_02.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGgMIa12JwO9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bhRQzALQtogb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sl4RvtetqAX",
        "outputId": "836c3c8e-ec79-4d52-bb84-4c740d073c04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   task  participant  trial  decision_type  choice  OEE1  OEE2  CT1  CT2\n",
            "0     0            0      0              0       1    88    86   46   48\n",
            "1     0            0      1              1       1    88    86   46   48\n",
            "2     0            0      2              0       1    88    86   46   48\n",
            "3     0            0      3              0       1    88    86   46   48\n",
            "4     0            0      4              0       1    88    86   46   48\n",
            "   task  participant  trial  decision_type  choice  OEE1  OEE2  CT1  CT2  \\\n",
            "0     0            0      0              0       1    88    86   46   48   \n",
            "1     0            0      1              1       1    88    86   46   48   \n",
            "2     0            0      2              0       1    88    86   46   48   \n",
            "3     0            0      3              0       1    88    86   46   48   \n",
            "4     0            0      4              0       1    88    86   46   48   \n",
            "\n",
            "   multiclass_target  \n",
            "0                  3  \n",
            "1                  4  \n",
            "2                  3  \n",
            "3                  3  \n",
            "4                  3  \n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/VSM_BRIMS_03_02.csv', header=0)\n",
        "\n",
        "df.columns = ['task', 'participant', 'trial', 'decision_type', 'choice', 'OEE1', 'OEE2', 'CT1', 'CT2']\n",
        "\n",
        "print(df.head())\n",
        "df['multiclass_target'] = df['choice'] * 3 + df['decision_type']\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC8KVryavijV",
        "outputId": "46630d60-9c86-4552-a7ff-1be8e8e2221b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task column is present.\n"
          ]
        }
      ],
      "source": [
        "if 'task' in df.columns:\n",
        "    print(\"Task column is present.\")\n",
        "else:\n",
        "    print(\"Task column is missing. Available columns:\", df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-tizUjntx9K",
        "outputId": "4d9b301c-6570-4a62-f8db-76a5686b9bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n"
          ]
        }
      ],
      "source": [
        "# iterative prompts\n",
        "import pandas as pd\n",
        "\n",
        "# question template\n",
        "question_template = (\n",
        "    \"Our manufacturing line has two sections with potential defect sources: pre-assembly (0) and assembly (1). \"\n",
        "    \"Pre-assembly takes {CT1} seconds with an Overall Equipment Effectiveness(OEE) rate of {OEE1}%, while assembly takes {CT2} seconds with an OEE rate of {OEE2}%. \"\n",
        "    \"To reduce total assembly time by 4 seconds, we need to identify which section can be shortened with minimal defect increase. \"\n",
        "    \"It's important to note that reducing cycle time will also lead to an increase in headcount costs.\"\n",
        "    \"There are two options: reduce pre-assembly time (0) or reduce assembly time (1).\\nQ: Which section do you choose to optimize? A: \"\n",
        ")\n",
        "text = []\n",
        "\n",
        "# Iterate over each task\n",
        "for task in df['task'].unique():\n",
        "    df_task = df[df['task'] == task]\n",
        "    print(task)\n",
        "    if not df_task.empty:\n",
        "        OEE1 = df_task['OEE1'].iloc[0]\n",
        "        OEE2 = df_task['OEE2'].iloc[0]\n",
        "        CT1 = df_task['CT1'].iloc[0]\n",
        "        CT2 = df_task['CT2'].iloc[0]\n",
        "        prompt = question_template.format(OEE1=OEE1, OEE2=OEE2, CT1=CT1, CT2=CT2)\n",
        "\n",
        "        # Apply the prompt to each row in the task\n",
        "        for index, row in df_task.iterrows():\n",
        "            text.append(prompt)\n",
        "    else:\n",
        "        \n",
        "        num_trials_expected = 15 \n",
        "        text.extend([\"Data not available for this task.\"] * num_trials_expected)\n",
        "\n",
        "\n",
        "if len(text) < len(df):\n",
        "    text.extend([\"Data missing due to processing error.\"] * (len(df) - len(text)))\n",
        "elif len(text) > len(df):\n",
        "    text = text[:len(df)]\n",
        "\n",
        "\n",
        "df['text'] = text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po2a_DVAwLD9",
        "outputId": "a5fefaa7-bfa0-4fc5-cbd8-c70bfa5b1c36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['task', 'participant', 'trial', 'decision_type', 'choice', 'OEE1', 'OEE2', 'CT1', 'CT2', 'multiclass_target', 'text'],\n",
              "    num_rows: 2012\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat = Dataset.from_pandas(df)\n",
        "dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kETLzEZ2wWH8",
        "outputId": "2cb15ab2-e2ba-4d95-aa7a-c746961b54ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'task': 0,\n",
              " 'participant': 0,\n",
              " 'trial': 0,\n",
              " 'decision_type': 0,\n",
              " 'choice': 1,\n",
              " 'OEE1': 88,\n",
              " 'OEE2': 86,\n",
              " 'CT1': 46,\n",
              " 'CT2': 48,\n",
              " 'multiclass_target': 3,\n",
              " 'text': \"Our manufacturing line has two sections with potential defect sources: pre-assembly (0) and assembly (1). Pre-assembly takes 46 seconds with an Overall Equipment Effectiveness(OEE) rate of 88%, while assembly takes 48 seconds with an OEE rate of 86%. To reduce total assembly time by 4 seconds, we need to identify which section can be shortened with minimal defect increase. It's important to note that reducing cycle time will also lead to an increase in headcount costs.There are two options: reduce pre-assembly time (0) or reduce assembly time (1).\\nQ: Which section do you choose to optimize? A: \"}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "511f0cf67a054704bdf903b1cc17bf63",
            "44b086fe2afe41a28f0f1e17c3047556",
            "0032dee78aca45369a611d27ebb6ed0a",
            "4b5d03db9ce64acda7a8ef0d9d72ef94",
            "79294ec749f8403187cecf746599ac59",
            "0cba4e95c14947478dc3d96efb93131a",
            "43fe4d31ab4543d2939291eb3086b328",
            "514d1fee5d1846f7887b9103828d5e4d",
            "6e0a9ca113a34e0e94345337145a226b",
            "15d7b0b492174834a8ea495a8303eb7a",
            "035afdc441cd4342a093186135303427",
            "b81a1fb89108487fb5bd363e3fa27d65",
            "4531128b704344a084f752f0d3dc9600",
            "116f5b65b5164dfcbd1cc99631bc56af",
            "cca141408aaf4e2e813bbc0ae11b5443",
            "74b0cc7be25646c19859d35df36a241f",
            "dd9de85eb0714945aaf2f55859da957a",
            "befb1cea90464aac9d565ade35af3353",
            "05eb48003e2f4cb08627bb3729a02b59",
            "2ca4d1b3bef74420a372f6646e93ff5c",
            "1e7b68ad1ec44f95bc08cb5a61c3a510",
            "57c77207b0a1425cb8ef7e1960263db4",
            "0ca70e0fd9fd44cea5266682fd70def5",
            "e5c42f42622c4e4c80d2535881ef2500",
            "720edcd04cb340af959e6bb31562dfb5",
            "6701971c487c482297c12f134557ce2d",
            "23d16fccf7ad4b29b56253221964f644",
            "8a6997ca0a964bc1ae708786ed6cf62b",
            "2dd4cb22b1df431296e52567fb48f743",
            "44691c61672c4e90bf20d3fe39dd85b1",
            "79a87e18063542a7a7ab4f6db1495914",
            "7e53bd001dd24ec49147f2ca7d603a73",
            "3ef5cbb109804da689940c4e23a10092",
            "10925300b8aa4868988fc366fd2f8754",
            "034bec7d768f4d4ab4d3d45947403ece",
            "8c4162875dbc477b93e86bd92add8874",
            "51260bcd2b1f45678278c0f435dde1b5",
            "eca6c74c72fc47ceb1c098a2c3ad3068",
            "5ada9d508c9a479791e2eb97fb0005f5",
            "344a9c50adb44d20877d3036d0249f70",
            "c0214e3062144018be93f8ac5c5b8297",
            "aab4685dde754a1596d3d305fac6aec9",
            "c865268c1afa43f6b7e71b55ecabb4f0",
            "629912a42d894678806bfd053883c681",
            "99bdb1678536440fab3b20ab2d1d8541",
            "6db572ce11ff4654aead68bea6e24b95",
            "0712c207336d4a928bf16eebb3e653f1",
            "f30cadb34dac4165b63f0fab790420e5",
            "be24d41d98de4718986b6177cf4a870e",
            "10ac7f09b05a45a29aa5e60a57c40787",
            "2b772b07d4b04bc4be0f7c778ff1b619",
            "4ae28b2282e2478683d55fd98a59ea9a",
            "d2c0d2c33b254a2599bfa0f8ef6f2259",
            "c35df69a0437448e8810b9703e9438e6",
            "98d2bd9cecdf402384d09fd3ea860a58",
            "767fff3dd69149209dd4a1ed30b19d3c",
            "b37246000d234959b25444d674b44b1e",
            "14ca286f97d944eb88f5c14960417f7f",
            "5e681d858fd7492ba72a0e4e3c4c302c",
            "d6c28929b4634e978cd431627b836847",
            "7635396e98e64312bae4b39d505f0cc3",
            "892db1ec57fa41129c5a92874f7e9251",
            "c945437ade364eb6af981c234679fa02",
            "46a8e17a13e44eb58292bb0bdd1af04e",
            "e0c23674a90e4549935545b19261208f",
            "8d9516519f4947da94c9a43b88d15ac3",
            "f97e2d384af64d9994737f044b21af15",
            "f96dd35631f74f7fb1476a41ab4dae74",
            "52c822db05a64289a55f9ef8985a793d",
            "5168e702a9b7498cad34e53f75029b6e",
            "b6f21e0d10914354ade519cdd5421181",
            "2c73b0dda3ac495290cba92ce4d99cf1",
            "4758799555e449ed9433c1d9d9925dde",
            "04a8c4efd487452b83d5ba9ae37c2154",
            "023ac5ef9fb74e41ad69b6da6ccb5a41",
            "a0c817a6ca4b4cbf89eee73e3c5bafaf",
            "1bf33285438c40b6acf54a5a0c4f3322"
          ]
        },
        "id": "uXOQVRZGwdQJ",
        "outputId": "01f40811-d3aa-4cbc-91a2-bef474f79b3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/784 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda:CUDA extension not installed.\n",
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda_old:CUDA extension not installed.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at TheBloke/LLama-2-7B-GPTQ were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"_name_or_path\": \"TheBloke/LLama-2-7B-GPTQ\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 11008,\n",
            "  \"max_length\": 4096,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"batch_size\": 1,\n",
            "    \"bits\": 4,\n",
            "    \"block_name_to_quantize\": null,\n",
            "    \"cache_block_outputs\": true,\n",
            "    \"damp_percent\": 0.01,\n",
            "    \"dataset\": null,\n",
            "    \"desc_act\": false,\n",
            "    \"exllama_config\": {\n",
            "      \"version\": 1\n",
            "    },\n",
            "    \"group_size\": 128,\n",
            "    \"max_input_length\": null,\n",
            "    \"model_seqlen\": null,\n",
            "    \"module_name_preceding_first_block\": null,\n",
            "    \"modules_in_block_to_quantize\": null,\n",
            "    \"pad_token_id\": null,\n",
            "    \"quant_method\": \"gptq\",\n",
            "    \"sym\": true,\n",
            "    \"tokenizer\": null,\n",
            "    \"true_sequential\": true,\n",
            "    \"use_cuda_fp16\": false,\n",
            "    \"use_exllama\": true\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.37.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Load model\n",
        "model_ckpt = 'TheBloke/LLama-2-7B-GPTQ'\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_ckpt,\n",
        "    device_map=\"auto\",\n",
        "    revision=\"main\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)\n",
        "\n",
        "print (model.config.to_json_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l18WLwKxEukj",
        "outputId": "bb1c25c0-293f-4957-c9bf-0a8d899f10bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.37.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e6da81b4f27476aa0a6b25577fbd84a",
            "80d5f8c2934e4e7584b2ecf875efbea5",
            "b93ad0062ec94a6aa742189ff1877c6b",
            "165280b056b3421097c33a9e9b4c792e",
            "f8bebbe4a6ae4bf8b6a5a283cc3986a0",
            "c1d2e3daa8e7486a8ce93a91b4cf9be6",
            "849115253b3648d6b105e7844120cb9a",
            "fd74302dc1ab421aa3fbda0646620a0d",
            "7fbfd5cd7e344fb29bb18a6e7cf5233a",
            "4a4c1231b5364646926248e6d4e25ba8",
            "48d8765d4b51496bacaaf0918376df8a"
          ]
        },
        "id": "xrZW9tlKwcML",
        "outputId": "0350253a-9a0d-4069-e86d-24cea00b6b14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2012 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'task': 0,\n",
              " 'participant': 0,\n",
              " 'trial': 0,\n",
              " 'decision_type': 0,\n",
              " 'choice': 1,\n",
              " 'OEE1': 88,\n",
              " 'OEE2': 86,\n",
              " 'CT1': 46,\n",
              " 'CT2': 48,\n",
              " 'multiclass_target': 3,\n",
              " 'text': \"Our manufacturing line has two sections with potential defect sources: pre-assembly (0) and assembly (1). Pre-assembly takes 46 seconds with an Overall Equipment Effectiveness(OEE) rate of 88%, while assembly takes 48 seconds with an OEE rate of 86%. To reduce total assembly time by 4 seconds, we need to identify which section can be shortened with minimal defect increase. It's important to note that reducing cycle time will also lead to an increase in headcount costs.There are two options: reduce pre-assembly time (0) or reduce assembly time (1).\\nQ: Which section do you choose to optimize? A: \",\n",
              " 'input_ids': [1,\n",
              "  8680,\n",
              "  12012,\n",
              "  3864,\n",
              "  1196,\n",
              "  756,\n",
              "  1023,\n",
              "  13926,\n",
              "  411,\n",
              "  7037,\n",
              "  23503,\n",
              "  8974,\n",
              "  29901,\n",
              "  758,\n",
              "  29899,\n",
              "  26936,\n",
              "  313,\n",
              "  29900,\n",
              "  29897,\n",
              "  322,\n",
              "  11470,\n",
              "  313,\n",
              "  29896,\n",
              "  467,\n",
              "  4721,\n",
              "  29899,\n",
              "  26936,\n",
              "  4893,\n",
              "  29871,\n",
              "  29946,\n",
              "  29953,\n",
              "  6923,\n",
              "  411,\n",
              "  385,\n",
              "  6811,\n",
              "  497,\n",
              "  11243,\n",
              "  666,\n",
              "  358,\n",
              "  26475,\n",
              "  20193,\n",
              "  29898,\n",
              "  29949,\n",
              "  17896,\n",
              "  29897,\n",
              "  6554,\n",
              "  310,\n",
              "  29871,\n",
              "  29947,\n",
              "  29947,\n",
              "  13667,\n",
              "  1550,\n",
              "  11470,\n",
              "  4893,\n",
              "  29871,\n",
              "  29946,\n",
              "  29947,\n",
              "  6923,\n",
              "  411,\n",
              "  385,\n",
              "  438,\n",
              "  17896,\n",
              "  6554,\n",
              "  310,\n",
              "  29871,\n",
              "  29947,\n",
              "  29953,\n",
              "  15543,\n",
              "  1763,\n",
              "  10032,\n",
              "  3001,\n",
              "  11470,\n",
              "  931,\n",
              "  491,\n",
              "  29871,\n",
              "  29946,\n",
              "  6923,\n",
              "  29892,\n",
              "  591,\n",
              "  817,\n",
              "  304,\n",
              "  12439,\n",
              "  607,\n",
              "  4004,\n",
              "  508,\n",
              "  367,\n",
              "  3273,\n",
              "  6419,\n",
              "  411,\n",
              "  13114,\n",
              "  23503,\n",
              "  7910,\n",
              "  29889,\n",
              "  739,\n",
              "  29915,\n",
              "  29879,\n",
              "  4100,\n",
              "  304,\n",
              "  4443,\n",
              "  393,\n",
              "  27668,\n",
              "  11412,\n",
              "  931,\n",
              "  674,\n",
              "  884,\n",
              "  3275,\n",
              "  304,\n",
              "  385,\n",
              "  7910,\n",
              "  297,\n",
              "  2343,\n",
              "  2798,\n",
              "  21544,\n",
              "  29889,\n",
              "  8439,\n",
              "  526,\n",
              "  1023,\n",
              "  3987,\n",
              "  29901,\n",
              "  10032,\n",
              "  758,\n",
              "  29899,\n",
              "  26936,\n",
              "  931,\n",
              "  313,\n",
              "  29900,\n",
              "  29897,\n",
              "  470,\n",
              "  10032,\n",
              "  11470,\n",
              "  931,\n",
              "  313,\n",
              "  29896,\n",
              "  467,\n",
              "  13,\n",
              "  29984,\n",
              "  29901,\n",
              "  8449,\n",
              "  4004,\n",
              "  437,\n",
              "  366,\n",
              "  6755,\n",
              "  304,\n",
              "  24656,\n",
              "  29973,\n",
              "  319,\n",
              "  29901,\n",
              "  29871],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "batch_tokenizer = lambda batch: tokenizer(batch['text'], padding=True, truncation=True)\n",
        "\n",
        "#  Tokenizing the dataset\n",
        "dat = dat.map(batch_tokenizer, batched=True)\n",
        "dat[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cOyPzejwv0l",
        "outputId": "85c5ee92-1d97-4d90-8762-f45facee05e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'task': 0,\n",
              " 'participant': 0,\n",
              " 'trial': 0,\n",
              " 'decision_type': 0,\n",
              " 'choice': 1,\n",
              " 'OEE1': 88,\n",
              " 'OEE2': 86,\n",
              " 'CT1': 46,\n",
              " 'CT2': 48,\n",
              " 'multiclass_target': 3,\n",
              " 'text': \"Our manufacturing line has two sections with potential defect sources: pre-assembly (0) and assembly (1). Pre-assembly takes 46 seconds with an Overall Equipment Effectiveness(OEE) rate of 88%, while assembly takes 48 seconds with an OEE rate of 86%. To reduce total assembly time by 4 seconds, we need to identify which section can be shortened with minimal defect increase. It's important to note that reducing cycle time will also lead to an increase in headcount costs.There are two options: reduce pre-assembly time (0) or reduce assembly time (1).\\nQ: Which section do you choose to optimize? A: \",\n",
              " 'input_ids': [1,\n",
              "  8680,\n",
              "  12012,\n",
              "  3864,\n",
              "  1196,\n",
              "  756,\n",
              "  1023,\n",
              "  13926,\n",
              "  411,\n",
              "  7037,\n",
              "  23503,\n",
              "  8974,\n",
              "  29901,\n",
              "  758,\n",
              "  29899,\n",
              "  26936,\n",
              "  313,\n",
              "  29900,\n",
              "  29897,\n",
              "  322,\n",
              "  11470,\n",
              "  313,\n",
              "  29896,\n",
              "  467,\n",
              "  4721,\n",
              "  29899,\n",
              "  26936,\n",
              "  4893,\n",
              "  29871,\n",
              "  29946,\n",
              "  29953,\n",
              "  6923,\n",
              "  411,\n",
              "  385,\n",
              "  6811,\n",
              "  497,\n",
              "  11243,\n",
              "  666,\n",
              "  358,\n",
              "  26475,\n",
              "  20193,\n",
              "  29898,\n",
              "  29949,\n",
              "  17896,\n",
              "  29897,\n",
              "  6554,\n",
              "  310,\n",
              "  29871,\n",
              "  29947,\n",
              "  29947,\n",
              "  13667,\n",
              "  1550,\n",
              "  11470,\n",
              "  4893,\n",
              "  29871,\n",
              "  29946,\n",
              "  29947,\n",
              "  6923,\n",
              "  411,\n",
              "  385,\n",
              "  438,\n",
              "  17896,\n",
              "  6554,\n",
              "  310,\n",
              "  29871,\n",
              "  29947,\n",
              "  29953,\n",
              "  15543,\n",
              "  1763,\n",
              "  10032,\n",
              "  3001,\n",
              "  11470,\n",
              "  931,\n",
              "  491,\n",
              "  29871,\n",
              "  29946,\n",
              "  6923,\n",
              "  29892,\n",
              "  591,\n",
              "  817,\n",
              "  304,\n",
              "  12439,\n",
              "  607,\n",
              "  4004,\n",
              "  508,\n",
              "  367,\n",
              "  3273,\n",
              "  6419,\n",
              "  411,\n",
              "  13114,\n",
              "  23503,\n",
              "  7910,\n",
              "  29889,\n",
              "  739,\n",
              "  29915,\n",
              "  29879,\n",
              "  4100,\n",
              "  304,\n",
              "  4443,\n",
              "  393,\n",
              "  27668,\n",
              "  11412,\n",
              "  931,\n",
              "  674,\n",
              "  884,\n",
              "  3275,\n",
              "  304,\n",
              "  385,\n",
              "  7910,\n",
              "  297,\n",
              "  2343,\n",
              "  2798,\n",
              "  21544,\n",
              "  29889,\n",
              "  8439,\n",
              "  526,\n",
              "  1023,\n",
              "  3987,\n",
              "  29901,\n",
              "  10032,\n",
              "  758,\n",
              "  29899,\n",
              "  26936,\n",
              "  931,\n",
              "  313,\n",
              "  29900,\n",
              "  29897,\n",
              "  470,\n",
              "  10032,\n",
              "  11470,\n",
              "  931,\n",
              "  313,\n",
              "  29896,\n",
              "  467,\n",
              "  13,\n",
              "  29984,\n",
              "  29901,\n",
              "  8449,\n",
              "  4004,\n",
              "  437,\n",
              "  366,\n",
              "  6755,\n",
              "  304,\n",
              "  24656,\n",
              "  29973,\n",
              "  319,\n",
              "  29901,\n",
              "  29871],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTRJ9YsOwx_E",
        "outputId": "fbb87efe-745a-464e-f673-38f494a61675"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['task', 'participant', 'trial', 'decision_type', 'choice', 'OEE1', 'OEE2', 'CT1', 'CT2', 'multiclass_target', 'text', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 2012\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
        "dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BpwCQRuJw17S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(42) # For reproducibility\n",
        "from transformers import AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHrMqaA3w4OZ",
        "outputId": "f8db3f80-d704-49b2-880a-c4e2e85408b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the model and moving it to the GPU if available\n",
        "if torch.cuda.is_available():  \n",
        "    device = torch.device('cuda')\n",
        "elif torch.backends.mps.is_available(): \n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NEdACKbLWhP"
      },
      "source": [
        "# Fine tuning for predicting decision making behavior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvXjs-AJ2psp",
        "outputId": "d0454b58-17dd-4f20-d358-99530d33cf8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in 'choice' column: 2012\n"
          ]
        }
      ],
      "source": [
        "num_rows = len(dat['choice'])\n",
        "print(\"Number of rows in 'choice' column:\", num_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p5t8SJ5_8sJd"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4awriyK8tw9",
        "outputId": "d12cde32-2ab7-4be6-b57e-d1b4dd0e2610"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['task', 'participant', 'trial', 'decision_type', 'choice', 'OEE1', 'OEE2', 'CT1', 'CT2', 'multiclass_target', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1609\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['task', 'participant', 'trial', 'decision_type', 'choice', 'OEE1', 'OEE2', 'CT1', 'CT2', 'multiclass_target', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 403\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Splitting the data into train and test sets\n",
        "dat = dat.train_test_split(test_size=.2, seed=42)\n",
        "dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "peqyti9u8w62",
        "outputId": "b05b01cf-c52f-472e-d57e-4d35ca5d9b20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.arrow_dataset.Dataset</b><br/>def __init__(arrow_table: Table, info: Optional[DatasetInfo]=None, split: Optional[NamedSplit]=None, indices_table: Optional[Table]=None, fingerprint: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py</a>A Dataset backed by an Arrow table.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 631);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(dat['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "37e3e83007074176910b03ff64cd4990",
            "c4f2f2c51fc1414d9400c814729dceb0",
            "2f7e5611dc934e62831ca32a804c7e38",
            "e52b31725b084b8088bbc1af5f50be54",
            "5fba67eb73514f468da54f182922a926",
            "ac09073cc8f8442fbaff3f93e7a03d9d",
            "113c067b802043d8baf0609debe2865b",
            "6b3d567c37af4708b5b66ad8818fa9b8",
            "9725e1a05dbd4ee0b5f232f42cfdc150",
            "51481b6e301d41328694adc746683144",
            "f2e3a7a4012944dcb9ba94c51c1063ae",
            "f6d6de9a944247fc9a789878bb2d05b4",
            "c5208ab8144e47178fc3d72ac27b91e2",
            "191dbeeee9e24ee6a46530864ad34454",
            "f11ee0b6457f4bbca7220148e57594ec",
            "de3ce30d7d15493f97413d465d4255fe",
            "6cd6fcdc94b049239fe7c2a11e323013",
            "abd3b5232d5a41f78a9e3d77c9c4eb14",
            "1224721dbd7f419f9640aae1a972aa06",
            "2886edb10f204cdbbbd18f2cf2c00cad",
            "ab3a9352245e4522884065b162157d29",
            "627e0c251a534316a7d9f0551f120044"
          ]
        },
        "id": "uBGS1RMJIK2-",
        "outputId": "e2d3d559-f08a-4846-a495-d55228b281b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/416 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/6.30M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading adapter weights from ybelkada/opt-350m-lora led to unexpected keys not found in the model:  ['model.decoder.layers.0.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.0.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.0.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.0.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.1.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.1.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.1.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.1.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.10.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.10.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.10.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.10.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.11.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.11.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.11.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.11.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.12.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.12.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.12.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.12.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.13.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.13.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.13.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.13.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.14.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.14.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.14.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.14.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.15.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.15.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.15.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.15.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.16.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.16.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.16.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.16.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.17.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.17.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.17.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.17.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.18.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.18.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.18.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.18.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.19.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.19.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.19.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.19.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.2.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.2.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.2.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.2.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.20.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.20.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.20.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.20.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.21.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.21.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.21.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.21.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.22.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.22.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.22.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.22.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.23.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.23.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.23.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.23.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.3.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.3.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.3.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.3.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.4.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.4.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.4.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.4.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.5.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.5.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.5.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.5.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.6.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.6.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.6.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.6.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.7.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.7.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.7.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.7.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.8.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.8.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.8.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.8.self_attn.v_proj.lora_B.default.weight', 'model.decoder.layers.9.self_attn.q_proj.lora_A.default.weight', 'model.decoder.layers.9.self_attn.q_proj.lora_B.default.weight', 'model.decoder.layers.9.self_attn.v_proj.lora_A.default.weight', 'model.decoder.layers.9.self_attn.v_proj.lora_B.default.weight']. \n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "peft_model_id = \"ybelkada/opt-350m-lora\"\n",
        "\n",
        "model.load_adapter(peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "b4f8c3e0c87b4cf49ee72ae458b03440",
            "de9f2e8d8910479cb7dfe326dc497b7b",
            "b6520bf0cc80425398703c1ea6d73dad",
            "35f10158c0d349a4b6330baeb4eae3be",
            "c7bb0551b86a4200b9a700b45141f2f7",
            "315a6ea6b0d241f1b4ed7a03154c1f92",
            "a93c31e3021e43ed8e23873270dad74b",
            "6612d55c352f45d699d727b5947749b3",
            "a0b78b0f6e06418795724987e91acb1d",
            "676d6ff459644673adc61763599e01e6",
            "d814e37f197c4e22ab472ba29dbb74d8",
            "d37826778db1416eb3daf524aed2cbbd",
            "1c634320be6d453592b7b0479b22f4d8",
            "c7c7bf6735954a1c98ecaa4ecd308e63",
            "646028b4bed24dbf95d0bc8e427c87ca",
            "c68543678c26446394c3e6a38d9cd688",
            "2a0ce0e325a946cfb7d4745c2051daea",
            "52be5e0f04b84122aadcaf80be5464c3",
            "550e46ea6a194d9da070f284b2791f39",
            "8307232aa6b0461bb285e3edfcaab640",
            "e3e694ee99b64672a90a687a7d9b52a3",
            "abe38708fd884bd7b183e16885d1361d"
          ]
        },
        "id": "O2btXXYxqL2K",
        "outputId": "881a2745-a8c8-4dfa-b146-5050c90196f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1609 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/403 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "train_dataset = dat['train']\n",
        "test_dataset = dat['test']\n",
        "\n",
        "\n",
        "def format_dataset(example):\n",
        "    example['labels'] = example['choice']\n",
        "    return example\n",
        "\n",
        "train_dataset = train_dataset.map(format_dataset, batched=False)\n",
        "test_dataset = test_dataset.map(format_dataset, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYVUDcAA3_XU",
        "outputId": "9c6a48d2-1398-4d5f-c9f5-78ef9b224050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.33658036 -0.821017   -0.43053366 ... -0.36542332  0.2037078\n",
            " -0.14681532]\n"
          ]
        }
      ],
      "source": [
        "#import cognitive vector\n",
        "file_path = '/content/drive/My Drive/mean_output8.csv'\n",
        "cog_data = pd.read_csv(file_path)\n",
        "cognitive_vector_data = cog_data.iloc[-1].values\n",
        "print (cognitive_vector_data)\n",
        "# Convert the numpy array to a PyTorch tensor\n",
        "cognitive_vector = torch.tensor(cognitive_vector_data, dtype=torch.float)\n",
        "\n",
        "cognitive_vector = torch.nn.Parameter(cognitive_vector)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd3az9GC8eUQ"
      },
      "outputs": [],
      "source": [
        "#import cognitivelayerwrapper and CognitiveLLaMA\n",
        "import torch\n",
        "from cognitiveModels import CognitiveLayerWrapper, CognitiveLLaMA\n",
        "\n",
        "model = CognitiveLLaMA(model, cognitive_vector, target_layer_num=8, multiplier=5, dropout_prob=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8onHDhYNRUcd"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def get_train_dataloader(self):\n",
        "        dataloader = super().get_train_dataloader()\n",
        "        #print(\"Sample batch from dataloader:\", next(iter(dataloader)))\n",
        "        return dataloader\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        #print(\"Received inputs in compute_loss:\", inputs)\n",
        "        if 'labels' not in inputs:\n",
        "            raise ValueError(\"Labels key missing in inputs during training.\")\n",
        "        labels = inputs.pop('labels').long()\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0] if isinstance(outputs, tuple) else outputs\n",
        "        loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qT2YkVKAalYF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    if isinstance(pred.predictions, tuple):\n",
        "        logits = pred.predictions[0]\n",
        "    else:\n",
        "        logits = pred.predictions\n",
        "\n",
        "    preds = logits.argmax(-1)\n",
        "\n",
        "    # Calculate probabilities and NLL loss using PyTorch\n",
        "    probabilities = F.softmax(torch.tensor(logits), dim=-1)\n",
        "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "    nll_loss = F.nll_loss(probabilities.log(), labels_tensor).item()\n",
        "\n",
        "\n",
        "    return {\n",
        "        'nll_loss': nll_loss\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VZTiYva1ZVQ",
        "outputId": "c5a2d7a1-afa6-443c-92e5-9d5bce413c23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "btUmgHJD_4Tp",
        "outputId": "dcf3ebae-36e4-456c-85e5-db99fdc77c26"
      },
      "outputs": [],
      "source": [
        "#huggingface trainer, to train the model\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "model.to(device)\n",
        "model_name = f\"{model_ckpt}-finetuned\"\n",
        "batch_size = 2\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= model_name,\n",
        "    save_safetensors = False,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    evaluation_strategy='epoch',\n",
        "    logging_strategy='epoch',\n",
        "    learning_rate=1e-5,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    gradient_accumulation_steps=2,\n",
        "    max_grad_norm=1.0,\n",
        "    optim='adamw_torch'\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model= model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_3mzwYcRoHQ",
        "outputId": "1a95adea-9cc8-4056-f1ac-bc675d3f85dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.6439151167869568, 0.6434608697891235, 0.6522118449211121, 0.6466344594955444, 0.6519626975059509, 0.6487606763839722, 0.6464627385139465, 0.6476824879646301, 0.646708071231842, 0.6475809812545776]\n"
          ]
        }
      ],
      "source": [
        "# Access the training history\n",
        "metrics_history = trainer.state.log_history\n",
        "\n",
        "# Extract the NLL loss from evaluation phases\n",
        "nll_values = [entry['eval_nll_loss'] for entry in metrics_history if 'eval_nll_loss' in entry]\n",
        "print(nll_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNBgNIDnS_Ff",
        "outputId": "ab72da59-1092-42a9-8bff-2c7842da6855"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming `nll_values` holds your NLL loss data from the metrics\n",
        "epochs = range(1, len(nll_values) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, nll_values, marker='o', linestyle='-', color='blue')\n",
        "plt.title('NLL Loss Across Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('NLL Loss')\n",
        "plt.grid(True)\n",
        "plt.xticks(epochs)  # Ensure all epoch numbers are marked\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TLVKkSNO-5k",
        "outputId": "a3f495a4-ee15-455f-d625-2af693398781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'training': False, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': OrderedDict([('dropout', Dropout(p=0.5, inplace=False)), ('cognitive_layer', CognitiveLayerWrapper(\n",
            "  (base_model): LlamaForCausalLM(\n",
            "    (model): LlamaModel(\n",
            "      (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
            "      (layers): ModuleList(\n",
            "        (0-31): 32 x LlamaDecoderLayer(\n",
            "          (self_attn): LlamaSdpaAttention(\n",
            "            (rotary_emb): LlamaRotaryEmbedding()\n",
            "            (k_proj): QuantLinear()\n",
            "            (o_proj): QuantLinear()\n",
            "            (q_proj): lora.QuantLinear(\n",
            "              (base_layer): QuantLinear()\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Dropout(p=0.05, inplace=False)\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=16, out_features=4096, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "              (quant_linear_module): QuantLinear()\n",
            "            )\n",
            "            (v_proj): lora.QuantLinear(\n",
            "              (base_layer): QuantLinear()\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Dropout(p=0.05, inplace=False)\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=16, out_features=4096, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "              (quant_linear_module): QuantLinear()\n",
            "            )\n",
            "          )\n",
            "          (mlp): LlamaMLP(\n",
            "            (act_fn): SiLU()\n",
            "            (down_proj): QuantLinear()\n",
            "            (gate_proj): QuantLinear()\n",
            "            (up_proj): QuantLinear()\n",
            "          )\n",
            "          (input_layernorm): LlamaRMSNorm()\n",
            "          (post_attention_layernorm): LlamaRMSNorm()\n",
            "        )\n",
            "      )\n",
            "      (norm): LlamaRMSNorm()\n",
            "    )\n",
            "    (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            "  )\n",
            ")), ('classifier', Linear(in_features=4096, out_features=2, bias=True))]), '_is_accelerate_prepared': True}\n"
          ]
        }
      ],
      "source": [
        "print (model.__dict__)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}